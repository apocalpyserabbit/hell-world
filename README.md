# 🎯 智能内容风控工作流 (RiskGuard)

本项目是针对 **字节跳动内容质量与数据服务平台 (CQC)** 场景搭建的 **端到端智能风控 Workflow**。它将大模型的**内容感知能力**与**运营的策略逻辑**解耦，实现高 ROI 的风控流程自动化。

**技术栈:** Coze Workflow, LLM (豆包/GPT-4o), Python 3.x, RAG (Search), JSON。

---

## 🚀 核心架构与贡献点

本项目架构严格遵循模型运营的最小闭环，确保了模型效果的可控性与业务策略的灵活性。

### 1. 业务流程与工程架构 (Workflow)
* **端到端自动化：** 搭建了 `Start → Search (RAG) → LLM (分类) → Code (决策) → End` 的完整业务链条，实现风险内容从输入到处置的自动化。
* **策略与模型解耦：** 将复杂的 **风险阈值判断** 逻辑实现在独立的 **Code 节点** 中，避免将业务策略写死在 Prompt 中，显著提升了策略的迭代速度和可维护性。

### 2. 模型效果与 PE 优化 (LLM)
* **CoT 精调：** 采用 Few-Shot 示例和思维链（CoT）Prompt，强制模型执行 **“关键词提取 → 语境校验 → 变体检测 → 最终判定”** 的四步推理。
* **RAG 增强：** 集成 `search_web` 工具，为 LLM 提供实时的网络语境，以应对黑话变体和突发热点舆情，增强了对**隐晦黑话**的识别能力。
* **结构化输出：** 强制模型输出包含 `risk_score` 和 `risk_label` 的 JSON 格式报告，为后续的策略引擎和数据分析提供了结构化数据资产。

### 3. 策略实现 (Code Engine)
* **风险分层策略：** 通过 Python 代码实现了基于风险类别的分层处置逻辑：
    * **政治敏感类：** 实行低阈值拦截 (`risk_score > 60`)。
    * **辱骂/引流类：** 实行高阈值拦截 (`risk_score >= 85`)。
* **工程健壮性：** 代码中加入了对 **LLM 输出的 JSON 字符串解析** (`json.loads`) 和 **数值类型强制转换** (`int()`) 的错误处理机制，确保了模型的输出能被下游系统稳定接收。

---

## ⚙️ 核心文件

| 文件名 | 内容描述 | 关键作用 |
| :--- | :--- | :--- |
| `coze_strategy_engine.py` | Code 节点最终运行的 Python 代码。 | 负责执行分层拦截策略。 |
| `llm_prompt_v1.md` | LLM 节点采用的完整 Prompt 文本。 | 定义模型的角色、CoT 思维链和输出格式。 |
